加载分词器...
加载模型...

Loading weights:   0%|          | 0/183 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/183 [00:00<00:00, 10180.35it/s, Materializing param=lm_head.weight]
Loading weights:   1%|          | 1/183 [00:00<00:00, 4634.59it/s, Materializing param=lm_head.weight] 
Loading weights:   1%|          | 2/183 [00:00<00:00, 5305.89it/s, Materializing param=model.language_model.embed_tokens.weight]
Loading weights:   1%|          | 2/183 [00:00<00:00, 2557.50it/s, Materializing param=model.language_model.embed_tokens.weight]
Loading weights:   2%|▏         | 3/183 [00:00<00:00, 3211.57it/s, Materializing param=model.language_model.layers.0.input_layernorm.weight]
Loading weights:   2%|▏         | 3/183 [00:00<00:00, 2790.00it/s, Materializing param=model.language_model.layers.0.input_layernorm.weight]
Loading weights:   2%|▏         | 4/183 [00:00<00:00, 3307.81it/s, Materializing param=model.language_model.layers.0.mlp.down_proj.weight]  
Loading weights:   2%|▏         | 4/183 [00:00<00:00, 3133.59it/s, Materializing param=model.language_model.layers.0.mlp.down_proj.weight]
Loading weights:   3%|▎         | 5/183 [00:00<00:00, 3547.28it/s, Materializing param=model.language_model.layers.0.mlp.gate_proj.weight]
Loading weights:   3%|▎         | 5/183 [00:00<00:00, 3392.35it/s, Materializing param=model.language_model.layers.0.mlp.gate_proj.weight]
Loading weights:   3%|▎         | 6/183 [00:00<00:00, 3739.91it/s, Materializing param=model.language_model.layers.0.mlp.up_proj.weight]  
Loading weights:   3%|▎         | 6/183 [00:00<00:00, 3596.15it/s, Materializing param=model.language_model.layers.0.mlp.up_proj.weight]
Loading weights:   4%|▍         | 7/183 [00:00<00:00, 3893.40it/s, Materializing param=model.language_model.layers.0.post_attention_layernorm.weight]
Loading weights:   4%|▍         | 7/183 [00:00<00:00, 3758.82it/s, Materializing param=model.language_model.layers.0.post_attention_layernorm.weight]
Loading weights:   4%|▍         | 8/183 [00:00<00:00, 4022.83it/s, Materializing param=model.language_model.layers.0.self_attn.k_proj.weight]        
Loading weights:   4%|▍         | 8/183 [00:00<00:00, 3901.68it/s, Materializing param=model.language_model.layers.0.self_attn.k_proj.weight]
Loading weights:   5%|▍         | 9/183 [00:00<00:00, 4124.64it/s, Materializing param=model.language_model.layers.0.self_attn.o_proj.weight]
Loading weights:   5%|▍         | 9/183 [00:00<00:00, 4010.28it/s, Materializing param=model.language_model.layers.0.self_attn.o_proj.weight]
Loading weights:   5%|▌         | 10/183 [00:00<00:00, 4206.08it/s, Materializing param=model.language_model.layers.0.self_attn.q_proj.weight]
Loading weights:   5%|▌         | 10/183 [00:00<00:00, 4098.40it/s, Materializing param=model.language_model.layers.0.self_attn.q_proj.weight]
Loading weights:   6%|▌         | 11/183 [00:00<00:00, 3759.26it/s, Materializing param=model.language_model.layers.0.self_attn.v_proj.weight]
Loading weights:   6%|▌         | 11/183 [00:00<00:00, 3678.92it/s, Materializing param=model.language_model.layers.0.self_attn.v_proj.weight]
Loading weights:   7%|▋         | 12/183 [00:00<00:00, 3848.28it/s, Materializing param=model.language_model.layers.1.input_layernorm.weight] 
Loading weights:   7%|▋         | 12/183 [00:00<00:00, 3622.28it/s, Materializing param=model.language_model.layers.1.input_layernorm.weight]
Loading weights:   7%|▋         | 13/183 [00:00<00:00, 3780.22it/s, Materializing param=model.language_model.layers.1.mlp.down_proj.weight]  
Loading weights:   7%|▋         | 13/183 [00:00<00:00, 3714.55it/s, Materializing param=model.language_model.layers.1.mlp.down_proj.weight]
Loading weights:   8%|▊         | 14/183 [00:00<00:00, 3860.13it/s, Materializing param=model.language_model.layers.1.mlp.gate_proj.weight]
Loading weights:   8%|▊         | 14/183 [00:00<00:00, 3767.74it/s, Materializing param=model.language_model.layers.1.mlp.gate_proj.weight]
Loading weights:   8%|▊         | 15/183 [00:00<00:00, 3913.57it/s, Materializing param=model.language_model.layers.1.mlp.up_proj.weight]  
Loading weights:   8%|▊         | 15/183 [00:00<00:00, 3767.34it/s, Materializing param=model.language_model.layers.1.mlp.up_proj.weight]
Loading weights:   9%|▊         | 16/183 [00:00<00:00, 3891.05it/s, Materializing param=model.language_model.layers.1.post_attention_layernorm.weight]
Loading weights:   9%|▊         | 16/183 [00:00<00:00, 3781.21it/s, Materializing param=model.language_model.layers.1.post_attention_layernorm.weight]
Loading weights:   9%|▉         | 17/183 [00:00<00:00, 3908.09it/s, Materializing param=model.language_model.layers.1.self_attn.k_proj.weight]        
Loading weights:   9%|▉         | 17/183 [00:00<00:00, 3590.83it/s, Materializing param=model.language_model.layers.1.self_attn.k_proj.weight]
Loading weights:  10%|▉         | 18/183 [00:00<00:00, 3701.22it/s, Materializing param=model.language_model.layers.1.self_attn.o_proj.weight]
Loading weights:  10%|▉         | 18/183 [00:00<00:00, 3655.87it/s, Materializing param=model.language_model.layers.1.self_attn.o_proj.weight]
Loading weights:  10%|█         | 19/183 [00:00<00:00, 3765.97it/s, Materializing param=model.language_model.layers.1.self_attn.q_proj.weight]
Loading weights:  10%|█         | 19/183 [00:00<00:00, 3721.83it/s, Materializing param=model.language_model.layers.1.self_attn.q_proj.weight]
Loading weights:  11%|█         | 20/183 [00:00<00:00, 3827.27it/s, Materializing param=model.language_model.layers.1.self_attn.v_proj.weight]
Loading weights:  11%|█         | 20/183 [00:00<00:00, 3784.28it/s, Materializing param=model.language_model.layers.1.self_attn.v_proj.weight]
Loading weights:  11%|█▏        | 21/183 [00:00<00:00, 3886.53it/s, Materializing param=model.language_model.layers.2.input_layernorm.weight] 
Loading weights:  11%|█▏        | 21/183 [00:00<00:00, 3766.86it/s, Materializing param=model.language_model.layers.2.input_layernorm.weight]
Loading weights:  12%|█▏        | 22/183 [00:00<00:00, 3716.86it/s, Materializing param=model.language_model.layers.2.mlp.down_proj.weight]  
Loading weights:  12%|█▏        | 22/183 [00:00<00:00, 3678.63it/s, Materializing param=model.language_model.layers.2.mlp.down_proj.weight]
Loading weights:  13%|█▎        | 23/183 [00:00<00:00, 3757.90it/s, Materializing param=model.language_model.layers.2.mlp.gate_proj.weight]
Loading weights:  13%|█▎        | 23/183 [00:00<00:00, 3664.96it/s, Materializing param=model.language_model.layers.2.mlp.gate_proj.weight]
Loading weights:  13%|█▎        | 24/183 [00:00<00:00, 3754.83it/s, Materializing param=model.language_model.layers.2.mlp.up_proj.weight]  
Loading weights:  13%|█▎        | 24/183 [00:00<00:00, 3720.28it/s, Materializing param=model.language_model.layers.2.mlp.up_proj.weight]
Loading weights:  14%|█▎        | 25/183 [00:00<00:00, 3748.66it/s, Materializing param=model.language_model.layers.2.post_attention_layernorm.weight]
Loading weights:  14%|█▎        | 25/183 [00:00<00:00, 3713.75it/s, Materializing param=model.language_model.layers.2.post_attention_layernorm.weight]
Loading weights:  14%|█▍        | 26/183 [00:00<00:00, 3793.64it/s, Materializing param=model.language_model.layers.2.self_attn.k_proj.weight]        
Loading weights:  14%|█▍        | 26/183 [00:00<00:00, 3672.52it/s, Materializing param=model.language_model.layers.2.self_attn.k_proj.weight]
Loading weights:  15%|█▍        | 27/183 [00:00<00:00, 3746.40it/s, Materializing param=model.language_model.layers.2.self_attn.o_proj.weight]
Loading weights:  15%|█▍        | 27/183 [00:00<00:00, 3611.51it/s, Materializing param=model.language_model.layers.2.self_attn.o_proj.weight]
Loading weights:  15%|█▌        | 28/183 [00:00<00:00, 3681.87it/s, Materializing param=model.language_model.layers.2.self_attn.q_proj.weight]
Loading weights:  15%|█▌        | 28/183 [00:00<00:00, 3456.27it/s, Materializing param=model.language_model.layers.2.self_attn.q_proj.weight]
Loading weights:  16%|█▌        | 29/183 [00:00<00:00, 3521.77it/s, Materializing param=model.language_model.layers.2.self_attn.v_proj.weight]
Loading weights:  16%|█▌        | 29/183 [00:00<00:00, 3452.30it/s, Materializing param=model.language_model.layers.2.self_attn.v_proj.weight]
Loading weights:  16%|█▋        | 30/183 [00:00<00:00, 3519.70it/s, Materializing param=model.language_model.layers.3.cross_attn.k_norm.weight]
Loading weights:  16%|█▋        | 30/183 [00:00<00:00, 3454.00it/s, Materializing param=model.language_model.layers.3.cross_attn.k_norm.weight]
Loading weights:  17%|█▋        | 31/183 [00:00<00:00, 3485.51it/s, Materializing param=model.language_model.layers.3.cross_attn.k_proj.weight]
Loading weights:  17%|█▋        | 31/183 [00:00<00:00, 3421.31it/s, Materializing param=model.language_model.layers.3.cross_attn.k_proj.weight]
Loading weights:  17%|█▋        | 32/183 [00:00<00:00, 3452.72it/s, Materializing param=model.language_model.layers.3.cross_attn.o_proj.weight]
Loading weights:  17%|█▋        | 32/183 [00:00<00:00, 3430.57it/s, Materializing param=model.language_model.layers.3.cross_attn.o_proj.weight]
Loading weights:  18%|█▊        | 33/183 [00:00<00:00, 3488.47it/s, Materializing param=model.language_model.layers.3.cross_attn.q_norm.weight]
Loading weights:  18%|█▊        | 33/183 [00:00<00:00, 3345.39it/s, Materializing param=model.language_model.layers.3.cross_attn.q_norm.weight]
Loading weights:  19%|█▊        | 34/183 [00:00<00:00, 3404.96it/s, Materializing param=model.language_model.layers.3.cross_attn.q_proj.weight]
Loading weights:  19%|█▊        | 34/183 [00:00<00:00, 3354.02it/s, Materializing param=model.language_model.layers.3.cross_attn.q_proj.weight]
Loading weights:  19%|█▉        | 35/183 [00:00<00:00, 3413.25it/s, Materializing param=model.language_model.layers.3.cross_attn.v_proj.weight]
Loading weights:  19%|█▉        | 35/183 [00:00<00:00, 3359.28it/s, Materializing param=model.language_model.layers.3.cross_attn.v_proj.weight]
Loading weights:  20%|█▉        | 36/183 [00:00<00:00, 3388.88it/s, Materializing param=model.language_model.layers.3.cross_attn_attn_gate]    
Loading weights:  20%|█▉        | 36/183 [00:00<00:00, 3344.44it/s, Materializing param=model.language_model.layers.3.cross_attn_attn_gate]
Loading weights:  20%|██        | 37/183 [00:00<00:00, 3401.48it/s, Materializing param=model.language_model.layers.3.cross_attn_mlp_gate] 
Loading weights:  20%|██        | 37/183 [00:00<00:00, 3383.39it/s, Materializing param=model.language_model.layers.3.cross_attn_mlp_gate]
Loading weights:  21%|██        | 38/183 [00:00<00:00, 3441.15it/s, Materializing param=model.language_model.layers.3.input_layernorm.weight]
Loading weights:  21%|██        | 38/183 [00:00<00:00, 3423.19it/s, Materializing param=model.language_model.layers.3.input_layernorm.weight]
Loading weights:  21%|██▏       | 39/183 [00:00<00:00, 3458.45it/s, Materializing param=model.language_model.layers.3.mlp.down_proj.weight]  
Loading weights:  21%|██▏       | 39/183 [00:00<00:00, 3439.26it/s, Materializing param=model.language_model.layers.3.mlp.down_proj.weight]
Loading weights:  22%|██▏       | 40/183 [00:00<00:00, 3491.03it/s, Materializing param=model.language_model.layers.3.mlp.gate_proj.weight]
Loading weights:  22%|██▏       | 40/183 [00:00<00:00, 3447.99it/s, Materializing param=model.language_model.layers.3.mlp.gate_proj.weight]
Loading weights:  22%|██▏       | 41/183 [00:00<00:00, 3497.39it/s, Materializing param=model.language_model.layers.3.mlp.up_proj.weight]  
Loading weights:  22%|██▏       | 41/183 [00:00<00:00, 3474.77it/s, Materializing param=model.language_model.layers.3.mlp.up_proj.weight]
Loading weights:  23%|██▎       | 42/183 [00:00<00:00, 3502.06it/s, Materializing param=model.language_model.layers.3.post_attention_layernorm.weight]
Loading weights:  23%|██▎       | 42/183 [00:00<00:00, 3455.49it/s, Materializing param=model.language_model.layers.3.post_attention_layernorm.weight]
Loading weights:  23%|██▎       | 43/183 [00:00<00:00, 3494.71it/s, Materializing param=model.language_model.layers.4.input_layernorm.weight]         
Loading weights:  23%|██▎       | 43/183 [00:00<00:00, 3444.72it/s, Materializing param=model.language_model.layers.4.input_layernorm.weight]
Loading weights:  24%|██▍       | 44/183 [00:00<00:00, 3465.46it/s, Materializing param=model.language_model.layers.4.mlp.down_proj.weight]  
Loading weights:  24%|██▍       | 44/183 [00:00<00:00, 3341.23it/s, Materializing param=model.language_model.layers.4.mlp.down_proj.weight]
Loading weights:  25%|██▍       | 45/183 [00:00<00:00, 3386.27it/s, Materializing param=model.language_model.layers.4.mlp.gate_proj.weight]
Loading weights:  25%|██▍       | 45/183 [00:00<00:00, 3350.68it/s, Materializing param=model.language_model.layers.4.mlp.gate_proj.weight]
Loading weights:  25%|██▌       | 46/183 [00:00<00:00, 3395.72it/s, Materializing param=model.language_model.layers.4.mlp.up_proj.weight]  
Loading weights:  25%|██▌       | 46/183 [00:00<00:00, 3371.92it/s, Materializing param=model.language_model.layers.4.mlp.up_proj.weight]
Loading weights:  26%|██▌       | 47/183 [00:00<00:00, 3366.50it/s, Materializing param=model.language_model.layers.4.post_attention_layernorm.weight]
Loading weights:  26%|██▌       | 47/183 [00:00<00:00, 3333.88it/s, Materializing param=model.language_model.layers.4.post_attention_layernorm.weight]
Loading weights:  26%|██▌       | 48/183 [00:00<00:00, 3376.83it/s, Materializing param=model.language_model.layers.4.self_attn.k_proj.weight]        
Loading weights:  26%|██▌       | 48/183 [00:00<00:00, 3326.61it/s, Materializing param=model.language_model.layers.4.self_attn.k_proj.weight]
Loading weights:  27%|██▋       | 49/183 [00:00<00:00, 3336.54it/s, Materializing param=model.language_model.layers.4.self_attn.o_proj.weight]
Loading weights:  27%|██▋       | 49/183 [00:00<00:00, 3219.31it/s, Materializing param=model.language_model.layers.4.self_attn.o_proj.weight]
Loading weights:  27%|██▋       | 50/183 [00:00<00:00, 3172.46it/s, Materializing param=model.language_model.layers.4.self_attn.q_proj.weight]
Loading weights:  27%|██▋       | 50/183 [00:00<00:00, 3136.87it/s, Materializing param=model.language_model.layers.4.self_attn.q_proj.weight]
Loading weights:  28%|██▊       | 51/183 [00:00<00:00, 3175.10it/s, Materializing param=model.language_model.layers.4.self_attn.v_proj.weight]
Loading weights:  28%|██▊       | 51/183 [00:00<00:00, 3111.32it/s, Materializing param=model.language_model.layers.4.self_attn.v_proj.weight]
Loading weights:  28%|██▊       | 52/183 [00:00<00:00, 3125.82it/s, Materializing param=model.language_model.layers.5.input_layernorm.weight] 
Loading weights:  28%|██▊       | 52/183 [00:00<00:00, 3063.51it/s, Materializing param=model.language_model.layers.5.input_layernorm.weight]
Loading weights:  29%|██▉       | 53/183 [00:00<00:00, 3015.85it/s, Materializing param=model.language_model.layers.5.mlp.down_proj.weight]  
Loading weights:  29%|██▉       | 53/183 [00:00<00:00, 3000.78it/s, Materializing param=model.language_model.layers.5.mlp.down_proj.weight]
Loading weights:  30%|██▉       | 54/183 [00:00<00:00, 3031.46it/s, Materializing param=model.language_model.layers.5.mlp.gate_proj.weight]
Loading weights:  30%|██▉       | 54/183 [00:00<00:00, 2993.28it/s, Materializing param=model.language_model.layers.5.mlp.gate_proj.weight]
Loading weights:  30%|███       | 55/183 [00:00<00:00, 3027.58it/s, Materializing param=model.language_model.layers.5.mlp.up_proj.weight]  
Loading weights:  30%|███       | 55/183 [00:00<00:00, 3006.36it/s, Materializing param=model.language_model.layers.5.mlp.up_proj.weight]
Loading weights:  31%|███       | 56/183 [00:00<00:00, 3017.60it/s, Materializing param=model.language_model.layers.5.post_attention_layernorm.weight]
Loading weights:  31%|███       | 56/183 [00:00<00:00, 3006.17it/s, Materializing param=model.language_model.layers.5.post_attention_layernorm.weight]
Loading weights:  31%|███       | 57/183 [00:00<00:00, 2990.87it/s, Materializing param=model.language_model.layers.5.self_attn.k_proj.weight]        
Loading weights:  31%|███       | 57/183 [00:00<00:00, 2963.77it/s, Materializing param=model.language_model.layers.5.self_attn.k_proj.weight]
Loading weights:  32%|███▏      | 58/183 [00:00<00:00, 2968.37it/s, Materializing param=model.language_model.layers.5.self_attn.o_proj.weight]
Loading weights:  32%|███▏      | 58/183 [00:00<00:00, 2938.89it/s, Materializing param=model.language_model.layers.5.self_attn.o_proj.weight]
Loading weights:  32%|███▏      | 59/183 [00:00<00:00, 2929.92it/s, Materializing param=model.language_model.layers.5.self_attn.q_proj.weight]
Loading weights:  32%|███▏      | 59/183 [00:00<00:00, 2908.16it/s, Materializing param=model.language_model.layers.5.self_attn.q_proj.weight]
Loading weights:  33%|███▎      | 60/183 [00:00<00:00, 2935.54it/s, Materializing param=model.language_model.layers.5.self_attn.v_proj.weight]
Loading weights:  33%|███▎      | 60/183 [00:00<00:00, 2924.29it/s, Materializing param=model.language_model.layers.5.self_attn.v_proj.weight]
Loading weights:  33%|███▎      | 61/183 [00:00<00:00, 2931.94it/s, Materializing param=model.language_model.layers.6.input_layernorm.weight] 
Loading weights:  33%|███▎      | 61/183 [00:00<00:00, 2899.70it/s, Materializing param=model.language_model.layers.6.input_layernorm.weight]
Loading weights:  34%|███▍      | 62/183 [00:00<00:00, 2925.56it/s, Materializing param=model.language_model.layers.6.mlp.down_proj.weight]  
Loading weights:  34%|███▍      | 62/183 [00:00<00:00, 2903.70it/s, Materializing param=model.language_model.layers.6.mlp.down_proj.weight]
Loading weights:  34%|███▍      | 63/183 [00:00<00:00, 2932.66it/s, Materializing param=model.language_model.layers.6.mlp.gate_proj.weight]
Loading weights:  34%|███▍      | 63/183 [00:00<00:00, 2877.60it/s, Materializing param=model.language_model.layers.6.mlp.gate_proj.weight]
Loading weights:  35%|███▍      | 64/183 [00:00<00:00, 2896.56it/s, Materializing param=model.language_model.layers.6.mlp.up_proj.weight]  
Loading weights:  35%|███▍      | 64/183 [00:00<00:00, 2877.06it/s, Materializing param=model.language_model.layers.6.mlp.up_proj.weight]
Loading weights:  36%|███▌      | 65/183 [00:00<00:00, 2869.58it/s, Materializing param=model.language_model.layers.6.post_attention_layernorm.weight]
Loading weights:  36%|███▌      | 65/183 [00:00<00:00, 2842.65it/s, Materializing param=model.language_model.layers.6.post_attention_layernorm.weight]
Loading weights:  36%|███▌      | 66/183 [00:00<00:00, 2861.26it/s, Materializing param=model.language_model.layers.6.self_attn.k_proj.weight]        
Loading weights:  36%|███▌      | 66/183 [00:00<00:00, 2841.73it/s, Materializing param=model.language_model.layers.6.self_attn.k_proj.weight]
Loading weights:  37%|███▋      | 67/183 [00:00<00:00, 2820.54it/s, Materializing param=model.language_model.layers.6.self_attn.o_proj.weight]
Loading weights:  37%|███▋      | 67/183 [00:00<00:00, 2793.81it/s, Materializing param=model.language_model.layers.6.self_attn.o_proj.weight]
Loading weights:  37%|███▋      | 68/183 [00:00<00:00, 2820.65it/s, Materializing param=model.language_model.layers.6.self_attn.q_proj.weight]
Loading weights:  37%|███▋      | 68/183 [00:00<00:00, 2788.38it/s, Materializing param=model.language_model.layers.6.self_attn.q_proj.weight]
Loading weights:  38%|███▊      | 69/183 [00:00<00:00, 2788.12it/s, Materializing param=model.language_model.layers.6.self_attn.v_proj.weight]
Loading weights:  38%|███▊      | 69/183 [00:00<00:00, 2779.87it/s, Materializing param=model.language_model.layers.6.self_attn.v_proj.weight]
Loading weights:  38%|███▊      | 70/183 [00:00<00:00, 2776.56it/s, Materializing param=model.language_model.layers.7.cross_attn.k_norm.weight]
Loading weights:  38%|███▊      | 70/183 [00:00<00:00, 2744.53it/s, Materializing param=model.language_model.layers.7.cross_attn.k_norm.weight]
Loading weights:  39%|███▉      | 71/183 [00:00<00:00, 2750.92it/s, Materializing param=model.language_model.layers.7.cross_attn.k_proj.weight]
Loading weights:  39%|███▉      | 71/183 [00:00<00:00, 2733.40it/s, Materializing param=model.language_model.layers.7.cross_attn.k_proj.weight]
Loading weights:  39%|███▉      | 72/183 [00:00<00:00, 2748.56it/s, Materializing param=model.language_model.layers.7.cross_attn.o_proj.weight]
Loading weights:  39%|███▉      | 72/183 [00:00<00:00, 2721.76it/s, Materializing param=model.language_model.layers.7.cross_attn.o_proj.weight]
Loading weights:  40%|███▉      | 73/183 [00:00<00:00, 2731.71it/s, Materializing param=model.language_model.layers.7.cross_attn.q_norm.weight]
Loading weights:  40%|███▉      | 73/183 [00:00<00:00, 2724.30it/s, Materializing param=model.language_model.layers.7.cross_attn.q_norm.weight]
Loading weights:  40%|████      | 74/183 [00:00<00:00, 2710.02it/s, Materializing param=model.language_model.layers.7.cross_attn.q_proj.weight]
Loading weights:  40%|████      | 74/183 [00:00<00:00, 2698.71it/s, Materializing param=model.language_model.layers.7.cross_attn.q_proj.weight]
Loading weights:  41%|████      | 75/183 [00:00<00:00, 2701.61it/s, Materializing param=model.language_model.layers.7.cross_attn.v_proj.weight]
Loading weights:  41%|████      | 75/183 [00:00<00:00, 2691.90it/s, Materializing param=model.language_model.layers.7.cross_attn.v_proj.weight]
Loading weights:  42%|████▏     | 76/183 [00:00<00:00, 2694.45it/s, Materializing param=model.language_model.layers.7.cross_attn_attn_gate]    
Loading weights:  42%|████▏     | 76/183 [00:00<00:00, 2687.64it/s, Materializing param=model.language_model.layers.7.cross_attn_attn_gate]
Loading weights:  42%|████▏     | 77/183 [00:00<00:00, 2708.86it/s, Materializing param=model.language_model.layers.7.cross_attn_mlp_gate] 
Loading weights:  42%|████▏     | 77/183 [00:00<00:00, 2696.13it/s, Materializing param=model.language_model.layers.7.cross_attn_mlp_gate]
Loading weights:  43%|████▎     | 78/183 [00:00<00:00, 2711.07it/s, Materializing param=model.language_model.layers.7.input_layernorm.weight]
Loading weights:  43%|████▎     | 78/183 [00:00<00:00, 2694.97it/s, Materializing param=model.language_model.layers.7.input_layernorm.weight]
Loading weights:  43%|████▎     | 79/183 [00:00<00:00, 2710.19it/s, Materializing param=model.language_model.layers.7.mlp.down_proj.weight]  
Loading weights:  43%|████▎     | 79/183 [00:00<00:00, 2697.63it/s, Materializing param=model.language_model.layers.7.mlp.down_proj.weight]
Loading weights:  44%|████▎     | 80/183 [00:00<00:00, 2709.65it/s, Materializing param=model.language_model.layers.7.mlp.gate_proj.weight]
Loading weights:  44%|████▎     | 80/183 [00:00<00:00, 2701.12it/s, Materializing param=model.language_model.layers.7.mlp.gate_proj.weight]
Loading weights:  44%|████▍     | 81/183 [00:00<00:00, 2719.28it/s, Materializing param=model.language_model.layers.7.mlp.up_proj.weight]  
Loading weights:  44%|████▍     | 81/183 [00:00<00:00, 2712.77it/s, Materializing param=model.language_model.layers.7.mlp.up_proj.weight]
Loading weights:  45%|████▍     | 82/183 [00:00<00:00, 2728.11it/s, Materializing param=model.language_model.layers.7.post_attention_layernorm.weight]
Loading weights:  45%|████▍     | 82/183 [00:00<00:00, 2721.55it/s, Materializing param=model.language_model.layers.7.post_attention_layernorm.weight]
Loading weights:  45%|████▌     | 83/183 [00:00<00:00, 2742.87it/s, Materializing param=model.language_model.layers.8.input_layernorm.weight]         
Loading weights:  45%|████▌     | 83/183 [00:00<00:00, 2714.02it/s, Materializing param=model.language_model.layers.8.input_layernorm.weight]
Loading weights:  46%|████▌     | 84/183 [00:00<00:00, 2726.27it/s, Materializing param=model.language_model.layers.8.mlp.down_proj.weight]  
Loading weights:  46%|████▌     | 84/183 [00:00<00:00, 2718.01it/s, Materializing param=model.language_model.layers.8.mlp.down_proj.weight]
Loading weights:  46%|████▋     | 85/183 [00:00<00:00, 2721.52it/s, Materializing param=model.language_model.layers.8.mlp.gate_proj.weight]
Loading weights:  46%|████▋     | 85/183 [00:00<00:00, 2715.24it/s, Materializing param=model.language_model.layers.8.mlp.gate_proj.weight]
Loading weights:  47%|████▋     | 86/183 [00:00<00:00, 2714.13it/s, Materializing param=model.language_model.layers.8.mlp.up_proj.weight]  
Loading weights:  47%|████▋     | 86/183 [00:00<00:00, 2668.23it/s, Materializing param=model.language_model.layers.8.mlp.up_proj.weight]
Loading weights:  48%|████▊     | 87/183 [00:00<00:00, 2666.69it/s, Materializing param=model.language_model.layers.8.post_attention_layernorm.weight]
Loading weights:  48%|████▊     | 87/183 [00:00<00:00, 2653.72it/s, Materializing param=model.language_model.layers.8.post_attention_layernorm.weight]
Loading weights:  48%|████▊     | 88/183 [00:00<00:00, 2652.77it/s, Materializing param=model.language_model.layers.8.self_attn.k_proj.weight]        
Loading weights:  48%|████▊     | 88/183 [00:00<00:00, 2646.72it/s, Materializing param=model.language_model.layers.8.self_attn.k_proj.weight]
Loading weights:  49%|████▊     | 89/183 [00:00<00:00, 2665.03it/s, Materializing param=model.language_model.layers.8.self_attn.o_proj.weight]
Loading weights:  49%|████▊     | 89/183 [00:00<00:00, 2657.25it/s, Materializing param=model.language_model.layers.8.self_attn.o_proj.weight]
Loading weights:  49%|████▉     | 90/183 [00:00<00:00, 2677.54it/s, Materializing param=model.language_model.layers.8.self_attn.q_proj.weight]
Loading weights:  49%|████▉     | 90/183 [00:00<00:00, 2672.69it/s, Materializing param=model.language_model.layers.8.self_attn.q_proj.weight]
Loading weights:  50%|████▉     | 91/183 [00:00<00:00, 2693.29it/s, Materializing param=model.language_model.layers.8.self_attn.v_proj.weight]
Loading weights:  50%|████▉     | 91/183 [00:00<00:00, 2687.14it/s, Materializing param=model.language_model.layers.8.self_attn.v_proj.weight]
Loading weights:  50%|█████     | 92/183 [00:00<00:00, 2707.16it/s, Materializing param=model.language_model.layers.9.input_layernorm.weight] 
Loading weights:  50%|█████     | 92/183 [00:00<00:00, 2702.25it/s, Materializing param=model.language_model.layers.9.input_layernorm.weight]
Loading weights:  51%|█████     | 93/183 [00:00<00:00, 2722.60it/s, Materializing param=model.language_model.layers.9.mlp.down_proj.weight]  
Loading weights:  51%|█████     | 93/183 [00:00<00:00, 2716.01it/s, Materializing param=model.language_model.layers.9.mlp.down_proj.weight]
Loading weights:  51%|█████▏    | 94/183 [00:00<00:00, 2736.14it/s, Materializing param=model.language_model.layers.9.mlp.gate_proj.weight]
Loading weights:  51%|█████▏    | 94/183 [00:00<00:00, 2731.50it/s, Materializing param=model.language_model.layers.9.mlp.gate_proj.weight]
Loading weights:  52%|█████▏    | 95/183 [00:00<00:00, 2751.77it/s, Materializing param=model.language_model.layers.9.mlp.up_proj.weight]  
Loading weights:  52%|█████▏    | 95/183 [00:00<00:00, 2747.12it/s, Materializing param=model.language_model.layers.9.mlp.up_proj.weight]
Loading weights:  52%|█████▏    | 96/183 [00:00<00:00, 2767.53it/s, Materializing param=model.language_model.layers.9.post_attention_layernorm.weight]
Loading weights:  52%|█████▏    | 96/183 [00:00<00:00, 2762.74it/s, Materializing param=model.language_model.layers.9.post_attention_layernorm.weight]
Loading weights:  53%|█████▎    | 97/183 [00:00<00:00, 2782.97it/s, Materializing param=model.language_model.layers.9.self_attn.k_proj.weight]        
Loading weights:  53%|█████▎    | 97/183 [00:00<00:00, 2777.67it/s, Materializing param=model.language_model.layers.9.self_attn.k_proj.weight]
Loading weights:  54%|█████▎    | 98/183 [00:00<00:00, 2797.50it/s, Materializing param=model.language_model.layers.9.self_attn.o_proj.weight]
Loading weights:  54%|█████▎    | 98/183 [00:00<00:00, 2792.90it/s, Materializing param=model.language_model.layers.9.self_attn.o_proj.weight]
Loading weights:  54%|█████▍    | 99/183 [00:00<00:00, 2812.13it/s, Materializing param=model.language_model.layers.9.self_attn.q_proj.weight]
Loading weights:  54%|█████▍    | 99/183 [00:00<00:00, 2807.36it/s, Materializing param=model.language_model.layers.9.self_attn.q_proj.weight]
Loading weights:  55%|█████▍    | 100/183 [00:00<00:00, 2827.28it/s, Materializing param=model.language_model.layers.9.self_attn.v_proj.weight]
Loading weights:  55%|█████▍    | 100/183 [00:00<00:00, 2822.60it/s, Materializing param=model.language_model.layers.9.self_attn.v_proj.weight]
Loading weights:  55%|█████▌    | 101/183 [00:00<00:00, 2842.28it/s, Materializing param=model.language_model.layers.10.input_layernorm.weight]
Loading weights:  55%|█████▌    | 101/183 [00:00<00:00, 2837.65it/s, Materializing param=model.language_model.layers.10.input_layernorm.weight]
Loading weights:  56%|█████▌    | 102/183 [00:00<00:00, 2857.44it/s, Materializing param=model.language_model.layers.10.mlp.down_proj.weight]  
Loading weights:  56%|█████▌    | 102/183 [00:00<00:00, 2852.68it/s, Materializing param=model.language_model.layers.10.mlp.down_proj.weight]
Loading weights:  56%|█████▋    | 103/183 [00:00<00:00, 2872.05it/s, Materializing param=model.language_model.layers.10.mlp.gate_proj.weight]
Loading weights:  56%|█████▋    | 103/183 [00:00<00:00, 2867.38it/s, Materializing param=model.language_model.layers.10.mlp.gate_proj.weight]
Loading weights:  57%|█████▋    | 104/183 [00:00<00:00, 2886.77it/s, Materializing param=model.language_model.layers.10.mlp.up_proj.weight]  
Loading weights:  57%|█████▋    | 104/183 [00:00<00:00, 2882.13it/s, Materializing param=model.language_model.layers.10.mlp.up_proj.weight]
Loading weights:  57%|█████▋    | 105/183 [00:00<00:00, 2901.33it/s, Materializing param=model.language_model.layers.10.post_attention_layernorm.weight]
Loading weights:  57%|█████▋    | 105/183 [00:00<00:00, 2896.52it/s, Materializing param=model.language_model.layers.10.post_attention_layernorm.weight]
Loading weights:  58%|█████▊    | 106/183 [00:00<00:00, 2915.65it/s, Materializing param=model.language_model.layers.10.self_attn.k_proj.weight]        
Loading weights:  58%|█████▊    | 106/183 [00:00<00:00, 2910.94it/s, Materializing param=model.language_model.layers.10.self_attn.k_proj.weight]
Loading weights:  58%|█████▊    | 107/183 [00:00<00:00, 2929.84it/s, Materializing param=model.language_model.layers.10.self_attn.o_proj.weight]
Loading weights:  58%|█████▊    | 107/183 [00:00<00:00, 2925.11it/s, Materializing param=model.language_model.layers.10.self_attn.o_proj.weight]
Loading weights:  59%|█████▉    | 108/183 [00:00<00:00, 2943.85it/s, Materializing param=model.language_model.layers.10.self_attn.q_proj.weight]
Loading weights:  59%|█████▉    | 108/183 [00:00<00:00, 2939.23it/s, Materializing param=model.language_model.layers.10.self_attn.q_proj.weight]
Loading weights:  60%|█████▉    | 109/183 [00:00<00:00, 2958.11it/s, Materializing param=model.language_model.layers.10.self_attn.v_proj.weight]
Loading weights:  60%|█████▉    | 109/183 [00:00<00:00, 2953.54it/s, Materializing param=model.language_model.layers.10.self_attn.v_proj.weight]
Loading weights:  60%|██████    | 110/183 [00:00<00:00, 2971.94it/s, Materializing param=model.language_model.layers.11.cross_attn.k_norm.weight]
Loading weights:  60%|██████    | 110/183 [00:00<00:00, 2966.65it/s, Materializing param=model.language_model.layers.11.cross_attn.k_norm.weight]
Loading weights:  61%|██████    | 111/183 [00:00<00:00, 2985.02it/s, Materializing param=model.language_model.layers.11.cross_attn.k_proj.weight]
Loading weights:  61%|██████    | 111/183 [00:00<00:00, 2980.43it/s, Materializing param=model.language_model.layers.11.cross_attn.k_proj.weight]
Loading weights:  61%|██████    | 112/183 [00:00<00:00, 2998.97it/s, Materializing param=model.language_model.layers.11.cross_attn.o_proj.weight]
Loading weights:  61%|██████    | 112/183 [00:00<00:00, 2994.40it/s, Materializing param=model.language_model.layers.11.cross_attn.o_proj.weight]
Loading weights:  62%|██████▏   | 113/183 [00:00<00:00, 3012.73it/s, Materializing param=model.language_model.layers.11.cross_attn.q_norm.weight]
Loading weights:  62%|██████▏   | 113/183 [00:00<00:00, 3008.06it/s, Materializing param=model.language_model.layers.11.cross_attn.q_norm.weight]
Loading weights:  62%|██████▏   | 114/183 [00:00<00:00, 3026.21it/s, Materializing param=model.language_model.layers.11.cross_attn.q_proj.weight]
Loading weights:  62%|██████▏   | 114/183 [00:00<00:00, 3021.55it/s, Materializing param=model.language_model.layers.11.cross_attn.q_proj.weight]
Loading weights:  63%|██████▎   | 115/183 [00:00<00:00, 3039.68it/s, Materializing param=model.language_model.layers.11.cross_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 115/183 [00:00<00:00, 3034.95it/s, Materializing param=model.language_model.layers.11.cross_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 116/183 [00:00<00:00, 3052.80it/s, Materializing param=model.language_model.layers.11.cross_attn_attn_gate]    
Loading weights:  63%|██████▎   | 116/183 [00:00<00:00, 3048.09it/s, Materializing param=model.language_model.layers.11.cross_attn_attn_gate]
Loading weights:  64%|██████▍   | 117/183 [00:00<00:00, 3066.15it/s, Materializing param=model.language_model.layers.11.cross_attn_mlp_gate] 
Loading weights:  64%|██████▍   | 117/183 [00:00<00:00, 3061.50it/s, Materializing param=model.language_model.layers.11.cross_attn_mlp_gate]
Loading weights:  64%|██████▍   | 118/183 [00:00<00:00, 3079.60it/s, Materializing param=model.language_model.layers.11.input_layernorm.weight]
Loading weights:  64%|██████▍   | 118/183 [00:00<00:00, 3074.96it/s, Materializing param=model.language_model.layers.11.input_layernorm.weight]
Loading weights:  65%|██████▌   | 119/183 [00:00<00:00, 3092.76it/s, Materializing param=model.language_model.layers.11.mlp.down_proj.weight]  
Loading weights:  65%|██████▌   | 119/183 [00:00<00:00, 3088.17it/s, Materializing param=model.language_model.layers.11.mlp.down_proj.weight]
Loading weights:  66%|██████▌   | 120/183 [00:00<00:00, 3105.65it/s, Materializing param=model.language_model.layers.11.mlp.gate_proj.weight]
Loading weights:  66%|██████▌   | 120/183 [00:00<00:00, 3101.07it/s, Materializing param=model.language_model.layers.11.mlp.gate_proj.weight]
Loading weights:  66%|██████▌   | 121/183 [00:00<00:00, 3118.36it/s, Materializing param=model.language_model.layers.11.mlp.up_proj.weight]  
Loading weights:  66%|██████▌   | 121/183 [00:00<00:00, 3113.72it/s, Materializing param=model.language_model.layers.11.mlp.up_proj.weight]
Loading weights:  67%|██████▋   | 122/183 [00:00<00:00, 3130.79it/s, Materializing param=model.language_model.layers.11.post_attention_layernorm.weight]
Loading weights:  67%|██████▋   | 122/183 [00:00<00:00, 3126.02it/s, Materializing param=model.language_model.layers.11.post_attention_layernorm.weight]
Loading weights:  67%|██████▋   | 123/183 [00:00<00:00, 3143.16it/s, Materializing param=model.language_model.layers.12.input_layernorm.weight]         
Loading weights:  67%|██████▋   | 123/183 [00:00<00:00, 3136.93it/s, Materializing param=model.language_model.layers.12.input_layernorm.weight]
Loading weights:  68%|██████▊   | 124/183 [00:00<00:00, 3153.54it/s, Materializing param=model.language_model.layers.12.mlp.down_proj.weight]  
Loading weights:  68%|██████▊   | 124/183 [00:00<00:00, 3148.59it/s, Materializing param=model.language_model.layers.12.mlp.down_proj.weight]
Loading weights:  68%|██████▊   | 125/183 [00:00<00:00, 3165.05it/s, Materializing param=model.language_model.layers.12.mlp.gate_proj.weight]
Loading weights:  68%|██████▊   | 125/183 [00:00<00:00, 3160.36it/s, Materializing param=model.language_model.layers.12.mlp.gate_proj.weight]
Loading weights:  69%|██████▉   | 126/183 [00:00<00:00, 3177.22it/s, Materializing param=model.language_model.layers.12.mlp.up_proj.weight]  
Loading weights:  69%|██████▉   | 126/183 [00:00<00:00, 3172.60it/s, Materializing param=model.language_model.layers.12.mlp.up_proj.weight]
Loading weights:  69%|██████▉   | 127/183 [00:00<00:00, 3189.43it/s, Materializing param=model.language_model.layers.12.post_attention_layernorm.weight]
Loading weights:  69%|██████▉   | 127/183 [00:00<00:00, 3184.70it/s, Materializing param=model.language_model.layers.12.post_attention_layernorm.weight]
Loading weights:  70%|██████▉   | 128/183 [00:00<00:00, 3201.40it/s, Materializing param=model.language_model.layers.12.self_attn.k_proj.weight]        
Loading weights:  70%|██████▉   | 128/183 [00:00<00:00, 3196.71it/s, Materializing param=model.language_model.layers.12.self_attn.k_proj.weight]
Loading weights:  70%|███████   | 129/183 [00:00<00:00, 3213.17it/s, Materializing param=model.language_model.layers.12.self_attn.o_proj.weight]
Loading weights:  70%|███████   | 129/183 [00:00<00:00, 3208.56it/s, Materializing param=model.language_model.layers.12.self_attn.o_proj.weight]
Loading weights:  71%|███████   | 130/183 [00:00<00:00, 3225.03it/s, Materializing param=model.language_model.layers.12.self_attn.q_proj.weight]
Loading weights:  71%|███████   | 130/183 [00:00<00:00, 3220.46it/s, Materializing param=model.language_model.layers.12.self_attn.q_proj.weight]
Loading weights:  72%|███████▏  | 131/183 [00:00<00:00, 3237.07it/s, Materializing param=model.language_model.layers.12.self_attn.v_proj.weight]
Loading weights:  72%|███████▏  | 131/183 [00:00<00:00, 3232.50it/s, Materializing param=model.language_model.layers.12.self_attn.v_proj.weight]
Loading weights:  72%|███████▏  | 132/183 [00:00<00:00, 3248.82it/s, Materializing param=model.language_model.layers.13.input_layernorm.weight] 
Loading weights:  72%|███████▏  | 132/183 [00:00<00:00, 3244.22it/s, Materializing param=model.language_model.layers.13.input_layernorm.weight]
Loading weights:  73%|███████▎  | 133/183 [00:00<00:00, 3260.56it/s, Materializing param=model.language_model.layers.13.mlp.down_proj.weight]  
Loading weights:  73%|███████▎  | 133/183 [00:00<00:00, 3255.95it/s, Materializing param=model.language_model.layers.13.mlp.down_proj.weight]
Loading weights:  73%|███████▎  | 134/183 [00:00<00:00, 3272.16it/s, Materializing param=model.language_model.layers.13.mlp.gate_proj.weight]
Loading weights:  73%|███████▎  | 134/183 [00:00<00:00, 3267.60it/s, Materializing param=model.language_model.layers.13.mlp.gate_proj.weight]
Loading weights:  74%|███████▍  | 135/183 [00:00<00:00, 3283.58it/s, Materializing param=model.language_model.layers.13.mlp.up_proj.weight]  
Loading weights:  74%|███████▍  | 135/183 [00:00<00:00, 3278.96it/s, Materializing param=model.language_model.layers.13.mlp.up_proj.weight]
Loading weights:  74%|███████▍  | 136/183 [00:00<00:00, 3293.96it/s, Materializing param=model.language_model.layers.13.post_attention_layernorm.weight]
Loading weights:  74%|███████▍  | 136/183 [00:00<00:00, 3289.12it/s, Materializing param=model.language_model.layers.13.post_attention_layernorm.weight]
Loading weights:  75%|███████▍  | 137/183 [00:00<00:00, 3304.82it/s, Materializing param=model.language_model.layers.13.self_attn.k_proj.weight]        
Loading weights:  75%|███████▍  | 137/183 [00:00<00:00, 3300.17it/s, Materializing param=model.language_model.layers.13.self_attn.k_proj.weight]
Loading weights:  75%|███████▌  | 138/183 [00:00<00:00, 3315.83it/s, Materializing param=model.language_model.layers.13.self_attn.o_proj.weight]
Loading weights:  75%|███████▌  | 138/183 [00:00<00:00, 3311.20it/s, Materializing param=model.language_model.layers.13.self_attn.o_proj.weight]
Loading weights:  76%|███████▌  | 139/183 [00:00<00:00, 3326.65it/s, Materializing param=model.language_model.layers.13.self_attn.q_proj.weight]
Loading weights:  76%|███████▌  | 139/183 [00:00<00:00, 3322.04it/s, Materializing param=model.language_model.layers.13.self_attn.q_proj.weight]
Loading weights:  77%|███████▋  | 140/183 [00:00<00:00, 3337.69it/s, Materializing param=model.language_model.layers.13.self_attn.v_proj.weight]
Loading weights:  77%|███████▋  | 140/183 [00:00<00:00, 3333.06it/s, Materializing param=model.language_model.layers.13.self_attn.v_proj.weight]
Loading weights:  77%|███████▋  | 141/183 [00:00<00:00, 3348.55it/s, Materializing param=model.language_model.layers.14.input_layernorm.weight] 
Loading weights:  77%|███████▋  | 141/183 [00:00<00:00, 3343.96it/s, Materializing param=model.language_model.layers.14.input_layernorm.weight]
Loading weights:  78%|███████▊  | 142/183 [00:00<00:00, 3359.53it/s, Materializing param=model.language_model.layers.14.mlp.down_proj.weight]  
Loading weights:  78%|███████▊  | 142/183 [00:00<00:00, 3354.97it/s, Materializing param=model.language_model.layers.14.mlp.down_proj.weight]
Loading weights:  78%|███████▊  | 143/183 [00:00<00:00, 3370.24it/s, Materializing param=model.language_model.layers.14.mlp.gate_proj.weight]
Loading weights:  78%|███████▊  | 143/183 [00:00<00:00, 3365.72it/s, Materializing param=model.language_model.layers.14.mlp.gate_proj.weight]
Loading weights:  79%|███████▊  | 144/183 [00:00<00:00, 3380.99it/s, Materializing param=model.language_model.layers.14.mlp.up_proj.weight]  
Loading weights:  79%|███████▊  | 144/183 [00:00<00:00, 3376.45it/s, Materializing param=model.language_model.layers.14.mlp.up_proj.weight]
Loading weights:  79%|███████▉  | 145/183 [00:00<00:00, 3391.78it/s, Materializing param=model.language_model.layers.14.post_attention_layernorm.weight]
Loading weights:  79%|███████▉  | 145/183 [00:00<00:00, 3387.16it/s, Materializing param=model.language_model.layers.14.post_attention_layernorm.weight]
Loading weights:  80%|███████▉  | 146/183 [00:00<00:00, 3402.35it/s, Materializing param=model.language_model.layers.14.self_attn.k_proj.weight]        
Loading weights:  80%|███████▉  | 146/183 [00:00<00:00, 3397.82it/s, Materializing param=model.language_model.layers.14.self_attn.k_proj.weight]
Loading weights:  80%|████████  | 147/183 [00:00<00:00, 3412.83it/s, Materializing param=model.language_model.layers.14.self_attn.o_proj.weight]
Loading weights:  80%|████████  | 147/183 [00:00<00:00, 3408.31it/s, Materializing param=model.language_model.layers.14.self_attn.o_proj.weight]
Loading weights:  81%|████████  | 148/183 [00:00<00:00, 3421.36it/s, Materializing param=model.language_model.layers.14.self_attn.q_proj.weight]
Loading weights:  81%|████████  | 148/183 [00:00<00:00, 3416.72it/s, Materializing param=model.language_model.layers.14.self_attn.q_proj.weight]
Loading weights:  81%|████████▏ | 149/183 [00:00<00:00, 3430.27it/s, Materializing param=model.language_model.layers.14.self_attn.v_proj.weight]
Loading weights:  81%|████████▏ | 149/183 [00:00<00:00, 3425.82it/s, Materializing param=model.language_model.layers.14.self_attn.v_proj.weight]
Loading weights:  82%|████████▏ | 150/183 [00:00<00:00, 3440.81it/s, Materializing param=model.language_model.layers.15.cross_attn.k_norm.weight]
Loading weights:  82%|████████▏ | 150/183 [00:00<00:00, 3436.41it/s, Materializing param=model.language_model.layers.15.cross_attn.k_norm.weight]
Loading weights:  83%|████████▎ | 151/183 [00:00<00:00, 3451.16it/s, Materializing param=model.language_model.layers.15.cross_attn.k_proj.weight]
Loading weights:  83%|████████▎ | 151/183 [00:00<00:00, 3446.80it/s, Materializing param=model.language_model.layers.15.cross_attn.k_proj.weight]
Loading weights:  83%|████████▎ | 152/183 [00:00<00:00, 3461.64it/s, Materializing param=model.language_model.layers.15.cross_attn.o_proj.weight]
Loading weights:  83%|████████▎ | 152/183 [00:00<00:00, 3457.23it/s, Materializing param=model.language_model.layers.15.cross_attn.o_proj.weight]
Loading weights:  84%|████████▎ | 153/183 [00:00<00:00, 3472.05it/s, Materializing param=model.language_model.layers.15.cross_attn.q_norm.weight]
Loading weights:  84%|████████▎ | 153/183 [00:00<00:00, 3467.70it/s, Materializing param=model.language_model.layers.15.cross_attn.q_norm.weight]
Loading weights:  84%|████████▍ | 154/183 [00:00<00:00, 3482.46it/s, Materializing param=model.language_model.layers.15.cross_attn.q_proj.weight]
Loading weights:  84%|████████▍ | 154/183 [00:00<00:00, 3477.96it/s, Materializing param=model.language_model.layers.15.cross_attn.q_proj.weight]
Loading weights:  85%|████████▍ | 155/183 [00:00<00:00, 3492.51it/s, Materializing param=model.language_model.layers.15.cross_attn.v_proj.weight]
Loading weights:  85%|████████▍ | 155/183 [00:00<00:00, 3488.18it/s, Materializing param=model.language_model.layers.15.cross_attn.v_proj.weight]
Loading weights:  85%|████████▌ | 156/183 [00:00<00:00, 3502.85it/s, Materializing param=model.language_model.layers.15.cross_attn_attn_gate]    
Loading weights:  85%|████████▌ | 156/183 [00:00<00:00, 3498.39it/s, Materializing param=model.language_model.layers.15.cross_attn_attn_gate]
Loading weights:  86%|████████▌ | 157/183 [00:00<00:00, 3513.02it/s, Materializing param=model.language_model.layers.15.cross_attn_mlp_gate] 
Loading weights:  86%|████████▌ | 157/183 [00:00<00:00, 3508.64it/s, Materializing param=model.language_model.layers.15.cross_attn_mlp_gate]
Loading weights:  86%|████████▋ | 158/183 [00:00<00:00, 3523.33it/s, Materializing param=model.language_model.layers.15.input_layernorm.weight]
Loading weights:  86%|████████▋ | 158/183 [00:00<00:00, 3518.99it/s, Materializing param=model.language_model.layers.15.input_layernorm.weight]
Loading weights:  87%|████████▋ | 159/183 [00:00<00:00, 3533.42it/s, Materializing param=model.language_model.layers.15.mlp.down_proj.weight]  
Loading weights:  87%|████████▋ | 159/183 [00:00<00:00, 3529.05it/s, Materializing param=model.language_model.layers.15.mlp.down_proj.weight]
Loading weights:  87%|████████▋ | 160/183 [00:00<00:00, 3543.37it/s, Materializing param=model.language_model.layers.15.mlp.gate_proj.weight]
Loading weights:  87%|████████▋ | 160/183 [00:00<00:00, 3538.96it/s, Materializing param=model.language_model.layers.15.mlp.gate_proj.weight]
Loading weights:  88%|████████▊ | 161/183 [00:00<00:00, 3553.09it/s, Materializing param=model.language_model.layers.15.mlp.up_proj.weight]  
Loading weights:  88%|████████▊ | 161/183 [00:00<00:00, 3548.20it/s, Materializing param=model.language_model.layers.15.mlp.up_proj.weight]
Loading weights:  89%|████████▊ | 162/183 [00:00<00:00, 3562.19it/s, Materializing param=model.language_model.layers.15.post_attention_layernorm.weight]
Loading weights:  89%|████████▊ | 162/183 [00:00<00:00, 3557.77it/s, Materializing param=model.language_model.layers.15.post_attention_layernorm.weight]
Loading weights:  89%|████████▉ | 163/183 [00:00<00:00, 3571.80it/s, Materializing param=model.language_model.layers.16.input_layernorm.weight]         
Loading weights:  89%|████████▉ | 163/183 [00:00<00:00, 3567.39it/s, Materializing param=model.language_model.layers.16.input_layernorm.weight]
Loading weights:  90%|████████▉ | 164/183 [00:00<00:00, 3581.29it/s, Materializing param=model.language_model.layers.16.mlp.down_proj.weight]  
Loading weights:  90%|████████▉ | 164/183 [00:00<00:00, 3576.88it/s, Materializing param=model.language_model.layers.16.mlp.down_proj.weight]
Loading weights:  90%|█████████ | 165/183 [00:00<00:00, 3590.72it/s, Materializing param=model.language_model.layers.16.mlp.gate_proj.weight]
Loading weights:  90%|█████████ | 165/183 [00:00<00:00, 3586.31it/s, Materializing param=model.language_model.layers.16.mlp.gate_proj.weight]
Loading weights:  91%|█████████ | 166/183 [00:00<00:00, 3600.22it/s, Materializing param=model.language_model.layers.16.mlp.up_proj.weight]  
Loading weights:  91%|█████████ | 166/183 [00:00<00:00, 3595.84it/s, Materializing param=model.language_model.layers.16.mlp.up_proj.weight]
Loading weights:  91%|█████████▏| 167/183 [00:00<00:00, 3609.57it/s, Materializing param=model.language_model.layers.16.post_attention_layernorm.weight]
Loading weights:  91%|█████████▏| 167/183 [00:00<00:00, 3605.12it/s, Materializing param=model.language_model.layers.16.post_attention_layernorm.weight]
Loading weights:  92%|█████████▏| 168/183 [00:00<00:00, 3618.88it/s, Materializing param=model.language_model.layers.16.self_attn.k_proj.weight]        
Loading weights:  92%|█████████▏| 168/183 [00:00<00:00, 3614.54it/s, Materializing param=model.language_model.layers.16.self_attn.k_proj.weight]
Loading weights:  92%|█████████▏| 169/183 [00:00<00:00, 3628.23it/s, Materializing param=model.language_model.layers.16.self_attn.o_proj.weight]
Loading weights:  92%|█████████▏| 169/183 [00:00<00:00, 3623.93it/s, Materializing param=model.language_model.layers.16.self_attn.o_proj.weight]
Loading weights:  93%|█████████▎| 170/183 [00:00<00:00, 3637.47it/s, Materializing param=model.language_model.layers.16.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 170/183 [00:00<00:00, 3633.21it/s, Materializing param=model.language_model.layers.16.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 171/183 [00:00<00:00, 3646.89it/s, Materializing param=model.language_model.layers.16.self_attn.v_proj.weight]
Loading weights:  93%|█████████▎| 171/183 [00:00<00:00, 3642.65it/s, Materializing param=model.language_model.layers.16.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 172/183 [00:00<00:00, 3656.20it/s, Materializing param=model.language_model.layers.17.input_layernorm.weight] 
Loading weights:  94%|█████████▍| 172/183 [00:00<00:00, 3651.97it/s, Materializing param=model.language_model.layers.17.input_layernorm.weight]
Loading weights:  95%|█████████▍| 173/183 [00:00<00:00, 3664.89it/s, Materializing param=model.language_model.layers.17.mlp.down_proj.weight]  
Loading weights:  95%|█████████▍| 173/183 [00:00<00:00, 3660.45it/s, Materializing param=model.language_model.layers.17.mlp.down_proj.weight]
Loading weights:  95%|█████████▌| 174/183 [00:00<00:00, 3673.23it/s, Materializing param=model.language_model.layers.17.mlp.gate_proj.weight]
Loading weights:  95%|█████████▌| 174/183 [00:00<00:00, 3668.91it/s, Materializing param=model.language_model.layers.17.mlp.gate_proj.weight]
Loading weights:  96%|█████████▌| 175/183 [00:00<00:00, 3682.37it/s, Materializing param=model.language_model.layers.17.mlp.up_proj.weight]  
Loading weights:  96%|█████████▌| 175/183 [00:00<00:00, 3678.02it/s, Materializing param=model.language_model.layers.17.mlp.up_proj.weight]
Loading weights:  96%|█████████▌| 176/183 [00:00<00:00, 3691.21it/s, Materializing param=model.language_model.layers.17.post_attention_layernorm.weight]
Loading weights:  96%|█████████▌| 176/183 [00:00<00:00, 3686.40it/s, Materializing param=model.language_model.layers.17.post_attention_layernorm.weight]
Loading weights:  97%|█████████▋| 177/183 [00:00<00:00, 3699.53it/s, Materializing param=model.language_model.layers.17.self_attn.k_proj.weight]        
Loading weights:  97%|█████████▋| 177/183 [00:00<00:00, 3695.13it/s, Materializing param=model.language_model.layers.17.self_attn.k_proj.weight]
Loading weights:  97%|█████████▋| 178/183 [00:00<00:00, 3708.23it/s, Materializing param=model.language_model.layers.17.self_attn.o_proj.weight]
Loading weights:  97%|█████████▋| 178/183 [00:00<00:00, 3703.84it/s, Materializing param=model.language_model.layers.17.self_attn.o_proj.weight]
Loading weights:  98%|█████████▊| 179/183 [00:00<00:00, 3716.90it/s, Materializing param=model.language_model.layers.17.self_attn.q_proj.weight]
Loading weights:  98%|█████████▊| 179/183 [00:00<00:00, 3712.60it/s, Materializing param=model.language_model.layers.17.self_attn.q_proj.weight]
Loading weights:  98%|█████████▊| 180/183 [00:00<00:00, 3725.53it/s, Materializing param=model.language_model.layers.17.self_attn.v_proj.weight]
Loading weights:  98%|█████████▊| 180/183 [00:00<00:00, 3721.25it/s, Materializing param=model.language_model.layers.17.self_attn.v_proj.weight]
Loading weights:  99%|█████████▉| 181/183 [00:00<00:00, 3734.18it/s, Materializing param=model.language_model.norm.weight]                      
Loading weights:  99%|█████████▉| 181/183 [00:00<00:00, 3729.99it/s, Materializing param=model.language_model.norm.weight]
Loading weights:  99%|█████████▉| 182/183 [00:00<00:00, 3743.26it/s, Materializing param=model.multi_modal_projector.bias]
Loading weights:  99%|█████████▉| 182/183 [00:00<00:00, 3739.12it/s, Materializing param=model.multi_modal_projector.bias]
Loading weights: 100%|██████████| 183/183 [00:00<00:00, 3752.64it/s, Materializing param=model.multi_modal_projector.weight]
Loading weights: 100%|██████████| 183/183 [00:00<00:00, 3748.54it/s, Materializing param=model.multi_modal_projector.weight]
Loading weights: 100%|██████████| 183/183 [00:00<00:00, 3739.24it/s, Materializing param=model.multi_modal_projector.weight]
[1mLegatoModel LOAD REPORT[0m from: ../legato-model
Key                                                                                                   | Status  | 
------------------------------------------------------------------------------------------------------+---------+-
model.vision_model.transformer.layers.{0...31}.mlp.fc1.bias                                           | MISSING | 
model.vision_model.post_tile_positional_embedding.embedding.weight                                    | MISSING | 
model.vision_model.transformer.layers.{0...31}.mlp.fc1.weight                                         | MISSING | 
model.vision_model.transformer.layers.{0...31}.self_attn.o_proj.weight                                | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.post_attention_layernorm.bias   | MISSING | 
model.vision_model.class_embedding                                                                    | MISSING | 
model.vision_model.transformer.layers.{0...31}.post_attention_layernorm.weight                        | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.gate_attn                       | MISSING | 
model.vision_model.transformer.layers.{0...31}.self_attn.v_proj.weight                                | MISSING | 
model.vision_model.transformer.layers.{0...31}.mlp.fc2.bias                                           | MISSING | 
model.vision_model.transformer.layers.{0...31}.self_attn.k_proj.weight                                | MISSING | 
model.vision_model.transformer.layers.{0...31}.input_layernorm.weight                                 | MISSING | 
model.vision_model.transformer.layers.{0...31}.self_attn.q_proj.weight                                | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.input_layernorm.weight          | MISSING | 
model.vision_model.transformer.layers.{0...31}.input_layernorm.bias                                   | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.gate_ffn                        | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.mlp.fc2.weight                  | MISSING | 
model.vision_model.transformer.layers.{0...31}.mlp.fc2.weight                                         | MISSING | 
model.vision_model.pre_tile_positional_embedding.gate                                                 | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.self_attn.q_proj.weight         | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.self_attn.o_proj.weight         | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.mlp.fc1.weight                  | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.self_attn.k_proj.weight         | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.post_attention_layernorm.weight | MISSING | 
model.vision_model.transformer.layers.{0...31}.post_attention_layernorm.bias                          | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.mlp.fc2.bias                    | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.self_attn.v_proj.weight         | MISSING | 
model.vision_model.pre_tile_positional_embedding.embedding.weight                                     | MISSING | 
model.vision_model.layernorm_post.weight                                                              | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.input_layernorm.bias            | MISSING | 
model.vision_model.gated_positional_embedding.gate                                                    | MISSING | 
model.vision_model.global_transformer.layers.{0, 1, 2, 3, 4, 5, 6, 7}.mlp.fc1.bias                    | MISSING | 
model.vision_model.gated_positional_embedding.tile_embedding.weight                                   | MISSING | 
model.vision_model.post_tile_positional_embedding.gate                                                | MISSING | 
model.vision_model.layernorm_post.bias                                                                | MISSING | 
model.vision_model.layernorm_pre.bias                                                                 | MISSING | 
model.vision_model.layernorm_pre.weight                                                               | MISSING | 
model.vision_model.gated_positional_embedding.embedding                                               | MISSING | 
model.vision_model.patch_embedding.weight                                                             | MISSING | 

[3mNotes:
- MISSING[3m	:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.[0m
使用设备: cuda
生成中...

=== 生成结果 ===
X:1
T:Test
M:4/4
L:1/8
K:C
 |$
V:1 treble
V:1
 GA G2 BGAB | c G2 G A4 | G G2 A B2 c2 | d G2 F G4 | GA G2 BGAB | %5
 c G2 G A4 |$ G G2 A B2 c2 | d G2 F G4 | G G2 A B2 c2 | d G2 F G4 | %10
 G G2 A
